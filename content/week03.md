---
title: "Week 3: 🔊 Speech Planning & Errors II"
tags: ["speech perception", "phonemes", "coarticulation", "brain", "categorical perception"]
summary: "Explores how humans perceive speech despite variability in the signal, using behavioral and neurological evidence."
---


## 📘 Overview
This week we extend Week 2’s production pipeline by digging deeper into **what errors tell us about planning**, how speakers **monitor and repair** speech, and how **articulation** shapes the final output. You’ll run an **error diary mini-study**, practice **self-monitoring** on short speaking tasks, and try **articulation drills** (minimal pairs & tongue twisters) to feel planning pressure and coarticulation effects.

---

## 🎯 Learning Goals
By the end of Week 3, you should be able to:

- Classify slips at **meaning/lemma**, **morphology**, and **phonology** with evidence-based reasoning.
- Explain how **prosodic frames** (syllable position, stress) constrain errors (e.g., onset↔onset exchanges).
- Describe how **self-monitoring** works (inner/outer loops) and identify **repair types** in your own speech.
- Show how **coarticulation** and **rate** influence planning and articulation.
- Design, run, and summarize a small **error diary study** with basic counts and interpretations.

---

## 📖 Required Reading
- **Traxler (1st ed.), Chapter 2, pp. 37–51** — *Speech Production & Comprehension* (continue production focus from Week 2).

---

## 🔑 Key Concepts & Mini-Explanations

### 🧩 From Slips to Mechanisms: What Patterns Reveal
- **Level-specific slips**  
  - *Semantic substitutions* (meaning neighbors: *dog → cat*) → **lemma** competition.  
  - *Phonological slips* (sound neighbors: *cat → mat*) → **phonological** encoding.  
  - *Morpheme errors* (*write–ed*, *cup of coffees*) → **morphology** placed on wrong stem/slot.
- **Prosodic constraints**  
  - **Syllable-position preservation:** exchanges tend to swap **onsets with onsets** (e.g., /k/↔/b/ at word beginnings), not onset↔coda.  
  - **Stress preservation:** exchanged segments/syllables often keep **stress patterns**, suggesting a **prosodic frame** guides sound placement.
- **Lexical bias**  
  - Slips more often form **real words** than non-words (e.g., *darn bore* instead of *barn dore*), implying joint influence of a **lexical level** during phonological planning.

### 🛠️ Monitoring & Repairs
- **Inner loop** (pre-articulatory): catches problems in the plan → **pauses (“uh/um”)**, reformulations.  
- **Outer loop** (post-articulatory): detects mismatches after speaking → **self-corrections** (“… sorry, I mean …”).  
- **Repair formats**  
  - **Restart**: “I went to the— I mean, I saw the …”  
  - **Substitution**: “She borrowed— no, *bought* the book.”  
  - **Editing terms**: “uh, um, I mean, sorry,” plus Chinese fillers like “呃 / 嗯 / 那个”.  
- **When monitoring helps:** complex utterances, high rate, multitasking; L2 speakers benefit from **planned pauses** and **previews** of key words.

### 👄 Articulation, Rate & Coarticulation
- **Coarticulation**: neighboring sounds overlap in time; anticipatory and carryover effects.  
  - Example: **/k/** in *key* vs. *coo* (tongue front vs. back) changes the burst quality.  
- **Speech rate**: faster speech increases planning load → more **anticipations**, more **restarts**.  
- **Planning units**: often a **phonological word** or **stress group**; longer units tax memory and increase error risk.

### 🔬 Mini-Study Logic (Error Diary)
- **Goal:** connect everyday slips to **planning stages** and **prosodic constraints**.  
- **Data to collect:** the exact utterance, intended target, **type** (semantic/phon/…); **position** (onset/coda), **stress**, **context** (fatigue, multitasking), **language** (EN/CN).  
- **Expected patterns:** more phonological slips under time pressure; onset↔onset exchanges; presence of editing terms before repairs.

---

## 📝 Pre-Class Activities
1. **Read** pp. 37–51 (skim Week 2 highlights).  
2. **Start your Error Diary** (collect ≥3 slips before class; include context, type, and guess the stage).  
3. **Articulation warm-up (3 mins)**: practice **minimal pairs** aloud (English):  
   - ship/sheep, bit/beat, cap/cab, light/right.  
   Note which pairs are hard and why.

---

## 💬 In-Class Activities

### 1) Error Diary Roundtable (12 min)
- In triads, each student presents **one slip** from their diary.  
- Group labels **type** and **stage**; note any **prosodic pattern** (onset/stress).  
- Quick share-out: 2 interesting cases.

### 2) Monitoring & Repair Lab (18 min)
- **Task A (pair)**: 60-second description (e.g., “your favorite trip”). Partner tallies: **fillers**, **restarts**, **repairs**. Swap.  
- **Task B (pair)**: Repeat with **slower rate + planned pauses** (silent 1-second commas). Compare counts.  
- **Discuss**: Did planned pauses reduce errors? Which repair types appeared?

### 3) Articulation Drills (15 min)
- **Minimal-pair relay** (teams): read lists quickly but clearly; teammates flag confusions.  
- **Tongue twisters** (English & Chinese): “black back bat,” “Truly rural,” “四是四, 十是十…”.  
- **Observation**: Which sounds trigger anticipations/perseverations? How does slowing down help?

### 4) Wrap Mini-Debrief (5 min)
- Add **one new slip** or **repair** from today to your diary with type/stage.

---

## 🔁 Post-Class Review
- **Summarize** your triad’s top **two patterns** (e.g., onset↔onset exchanges; more fillers at fast rate).  
- **Reflection (100–120 words):** Which **monitoring strategy** helped you most (planned pauses, previewing nouns, slower onset)?  
- **Update** your error diary to **5 total entries** with types, stages, and brief reasoning.

---

## 🏠 Homework
- **Textbook “Test Yourself”** (Ch. 2, production pages): items related to errors/monitoring.  
- **Mini-Study Report (1 page, bullet format ok):**  
  - Table of your **5 slips** (quote, intended target, **type**, **stage**, **position/stress**, **context**).  
  - **Counts** by type; 2–3 sentences interpreting what this suggests about planning.  
- **Optional:** 60-sec self-recording; annotate all **fillers/restarts/repairs**.

---

## 🧩 Self-Check Questions
**Q1.** Why do many exchanges preserve syllable **position** (onset→onset) and **stress**?  
<!--*A:* Because sounds are slotted into a **prosodic frame** during phonological encoding; the frame constrains where segments can go.*-->

**Q2.** What evidence suggests distinct **lemma** vs. **phonology** stages?  
<!--*A:* Semantic substitutions (meaning neighbors) vs. phonological slips (sound neighbors) dissociate; TOTs often access meaning but not full phonology.*-->

**Q3.** How can planned pauses reduce errors in L2 speech?  
<!--*A:* They give the **inner monitor** time to check the plan, lowering anticipations and restarts, especially around complex words.*-->

**Q4.** Give one **morpheme error** and the implicated stage.  
<!--*A:* “He write-ed the essay” → morpheme attached to wrong stem; **morphological** slotting during formulation.*-->

**Q5.** What pattern would support **lexical bias** in slips?  
<!--*A:* Slips that form **real words** occur more than phonotactically possible non-words (e.g., *darn bore* over *barn dore*).*-->

---

## 🧰 Key Terms
**Prosodic frame**, **Onset/Coda**, **Stress preservation**, **Lexical bias**, **Semantic substitution**, **Phonological slip**, **Morpheme error**, **Anticipation/Perseveration**, **Restart**, **Substitution repair**, **Editing term**, **Coarticulation**, **Monitoring (inner/outer loops)**.

---

## 🌐 Optional Resources
- Short videos/demos on **coarticulation** and **tongue twisters** (practice slowly → faster).  
- Articles or blog posts on **speech errors** and **self-monitoring** in second language speech.

---

### ✅ How to use these notes
- **Before class:** read; start your **error diary**; try the minimal pairs.  
- **During class:** apply the labels; run monitoring & drill tasks carefully.  
- **After class:** complete the **mini-study report** and practice the pause strategy in everyday speaking.

















<!--
## 📘 Overview

Have you ever thought you heard someone say something… only to realize you misunderstood completely? Or found it harder to understand speech in a noisy room? This week, we explore how our brain manages to decode rapid, variable, and noisy speech signals—a process more complex than it seems.

We'll investigate how **speech perception** works, why it’s so challenging, how we perceive categories of sounds, and how **what we see** can influence what we hear.

---

## 🎯 Learning Goals

By the end of this week, you should be able to:

- Explain why **speech perception** is difficult and identify key sources of variability.
- Define and illustrate **coarticulation** and **categorical perception**.
- Describe and interpret the **McGurk effect**.
- Compare and critique major **theories of speech perception**.
- Identify the **brain regions** involved in speech processing.

---

## 📖 Required Reading

- **Chapter 2 (pp. 51–71)** from *Introduction to Psycholinguistics: Understanding Language Science* by Matthew Traxler.

---

## 🧠 Core Concepts

### 🔄 Why Is Speech Perception Hard?

- **Fast & continuous**: Speech averages ~10–15 phonemes/sec, with no clear word boundaries.
- **Variability**: Sounds change depending on speaker, rate, emotion, and surrounding sounds (e.g., /t/ in “top” vs. “stop” vs. “cat”).
- **Lack of invariance**: There's no one-to-one mapping from sound to phoneme category.
- **Coarticulation**: Sounds influence each other (e.g., “boot” vs. “beet”).

---

### 🎨 Coarticulation & Categorical Perception

- **Coarticulation**: Speech sounds blend; upcoming sounds affect how current ones are produced and perceived.
  - Try saying "key" and "coo"—notice how /k/ differs.
- **Categorical Perception**:
  - We hear speech as **categories**, not continuous sounds.
  - Classic study: Liberman et al. (1957) showed listeners hear a clear switch between /ba/ and /pa/ as VOT changes.
  - **Why?** This makes perception faster and more robust to noise.

---

### 👁️ McGurk Effect & Multisensory Integration

- **McGurk effect** (McGurk & MacDonald, 1976):
  - Visual /ga/ + auditory /ba/ → perceived /da/.
  - Shows **visual input** influences what we hear.
- **Why important?**
  - Speech perception is **multimodal**—we don’t just use sound!
  - Especially helpful in **noisy environments** (Sumby & Pollack, 1954).

---

### 🧬 Theories of Speech Perception

| Theory            | Core Idea                                | Support                            | Limitations                          |
|------------------|-------------------------------------------|------------------------------------|--------------------------------------|
| **Motor Theory**  | Perceive speech by simulating gestures   | McGurk effect, motor cortex data   | Doesn’t explain all speech sounds    |
| **Auditory Theory** | General auditory system handles speech | Animal & infant studies            | Lacks detail on context/articulation |
| **TRACE Model**   | Interactive layers: features, phonemes, words | Ganong effect, lexical influence | Computationally complex              |

---

### 🧠 Speech Perception & the Brain

- **Superior temporal gyrus**: early auditory processing.
- **Wernicke’s area**: comprehension; damage → fluent aphasia.
- **Dual Stream Model** (Hickok & Poeppel, 2007):
  - **Ventral stream**: sound → meaning.
  - **Dorsal stream**: sound → motor mapping.

---

## 📝 Pre-Class Activities

Complete these before class to prepare for discussion and in-class tasks:

1. ✅ **Read Chapter 2 (pp. 51–71)** carefully. Focus on McGurk effect, coarticulation, and theory comparisons.
2. 👂 **Try this demo**:  
   - [McGurk Effect Demo](https://www.youtube.com/watch?v=G-lN8vWm3m0)  
   - Watch with eyes open, then closed. What do you hear each time?
3. 🎧 **Optional Podcast**:  
   - *Science Vs – Your Brain on Language* (Spotify or Apple Podcasts)

---

## 💬 In-Class Activities

- 🎧 **Mumbled Messages**: Distorted speech listening challenge.
- 👅 **Coarticulation Demos**: Say "ban" vs. "bun"; observe articulation changes.
- 🧪 **Categorical Perception Activity**: Vote when /ba/ becomes /pa/.
- 🎥 **McGurk Effect Video**: Test visual-auditory integration.
- 👄 **Lipreading Challenge**: Can you guess what's said without sound?
- 👥 **Theory Debate Groups**: Each group defends one theory of speech perception.

---

## 🔁 Post-Class Review

After class, reinforce your learning by:

1. 📚 **Re-reading** key sections on McGurk effect and speech theories.
2. ✍️ **Reflection Prompt**:
   > When you misunderstood someone recently, what clues helped you recover the meaning—sound, context, or visual cues?

3. 📝 **Mini Task**: 
   - Observe 1 instance where speech was unclear (e.g., in public or online).
   - Describe how you figured out what the speaker meant (~100 words).

4. 🧠 **Extra Resource**:  
   [Laurel/Yanny Illusion – Which do you hear?](https://www.youtube.com/watch?v=7X_WvGAhMlQ)

---

## 🏠 Homework

- 📖 Revisit Chapter 2 (pp. 60–71), focusing on speech perception theories and neurobiological evidence.
- ✍️ Complete 2 *Test Yourself* questions related to speech perception.
- 🔍 **Optional Research Brief**: Find and summarize one real-world application of speech perception research (e.g., voice assistants, hearing aids, language learning).

---

## 🔜 Looking Ahead

Next week we dive into how we **recognize words**—fast and with incredible precision. We’ll explore the mental **lexicon**, **semantic priming**, and what happens when you read a word like “butter” and suddenly crave toast.

-->



<!--
## 📘 Overview

Speech perception is a remarkable cognitive achievement: we can recognize spoken words rapidly and accurately, even though the signal is noisy, fast, and highly variable across speakers. This week, we explore how listeners parse the speech stream into discrete phonemes and words, how the brain supports these processes, and what speech illusions like the **McGurk effect** reveal about auditory-visual integration.

---

## 🧠 Core Concepts

### The Speech Perception Challenge

- The **acoustic signal is continuous**, but we perceive **discrete phonemes**.
- Phoneme boundaries are often **blurred** due to **coarticulation**.
- There is **no simple one-to-one mapping** between sound and phoneme.

### Categorical Perception

- Listeners perceive sounds along a continuum (e.g., /b/ to /p/) as **distinct categories**.
- **Voice Onset Time (VOT)** is used to test this: e.g., /ba/ vs. /pa/
- Perception is **all-or-none**, not gradual.

### Coarticulation

- Sounds influence each other in speech (e.g., the /k/ in "key" vs. "cool").
- Listeners use **contextual cues** and **expectations** to resolve ambiguity:contentReference[oaicite:0]{index=0}.

### Multimodal Integration & the McGurk Effect

- **McGurk Effect**: seeing [ga] + hearing [ba] = perceiving [da]
- Shows that speech perception integrates **visual** and **auditory** information.
- Demonstrates the **constructive nature** of perception.

### Theories of Speech Perception

| Theory | Core Idea |
|--------|-----------|
| **Motor Theory** | Speech perception involves accessing motor programs used for production. |
| **General Auditory Approach** | Listeners use general sound-processing mechanisms to perceive speech. |
| **Cohort Model (intro)** | Word recognition begins with a cohort of candidates, narrowed as more input arrives. |

### Neurological Evidence

- Brain imaging shows activity in **superior temporal gyrus** and **Broca’s/Wernicke’s areas** during speech perception.
- Studies of **brain-damaged patients** reveal that different parts of the brain handle **phonemic discrimination** and **comprehension**.

---

## 📚 Reading

- Traxler (2012), Chapter 2: *Speech Production and Comprehension* (pp. 51–71)

---

## 🏷️ Key Terms

| Term | Definition |
|------|------------|
| **Categorical Perception** | Perceiving sounds as belonging to distinct categories despite acoustic overlap |
| **Coarticulation** | Influence of surrounding sounds on the articulation of a phoneme |
| **McGurk Effect** | A perceptual illusion where visual and auditory inputs mismatch |
| **Voice Onset Time (VOT)** | The time between release of a consonant and onset of vocal cord vibration |
| **Motor Theory** | Theory that speech perception activates speech production mechanisms |
| **Phoneme Restoration** | The brain fills in missing phonemes based on context |

---

## 🧪 Examples & In-Class Activities

### 🎧 VOT Demonstration

- Students listen to a /ba/–/pa/ continuum.
- Discuss how they switch categories despite gradual changes.

### 🎥 McGurk Effect

- Play a video demo where the visual and auditory signals mismatch.
- Students report what they hear—often an illusory blend.
- Discuss how the brain integrates inputs.

### 🧠 Brain Tour (Mini Lecture + Discussion)

- Show diagrams of speech processing areas.
- Briefly compare brain areas involved in production vs. perception.

### 🔁 Perception Challenge

- Present coarticulated words out of context.
- Ask students to identify phonemes—then show how context changes perception.

---

## ❓ Self-Check Questions

1. Why is speech perception considered a "computational problem"?
2. What is categorical perception, and how is it tested?
3. What does the McGurk effect reveal about speech perception?
4. How do theories of speech perception differ in their explanation of phoneme recognition?
5. What role does the brain play in resolving ambiguity during speech perception?

---

## 🧩 Practice Prompt (Adapted from the Textbook)

> Imagine a listener hears the syllable “da” while seeing someone mouth “ga.”  
> 1. What might they report hearing?  
> 2. Which theory best explains this?  
> 3. How does this show the difference between perception and acoustics?

---

## 🔁 Related Chapters

- Chapter 1: *Introduction to Language Science*
- Chapter 3: *Word Processing* (focus on lexical access after phoneme identification)


<!--

## 🧠 Chapter 3 Lecture Notes: Language Acquisition I

How do children acquire language with such speed and accuracy, even before formal instruction? In this chapter, we explore the early stages of language development and theories that explain how humans acquire language.

---

## 📘 Core Topics & Concepts

### 1. What Is Language Acquisition?

* **Language acquisition**: the process by which humans learn their native language(s)
* Involves phonology, morphology, syntax, semantics, and pragmatics
* Begins *before birth* and continues into early childhood

> 🧠 **In class**: We’ll listen to early infant sounds and trace the developmental stages of speech.

---

### 2. Early Developmental Milestones

#### Prelinguistic Development

* **Prenatal**: fetuses respond to rhythm and intonation
* **0–6 months**: cooing, turn-taking, preference for native language sounds
* **6–12 months**: babbling (canonical and variegated), gesture use

#### First Words & Beyond

* **12 months**: first words typically emerge
* **18–24 months**: vocabulary explosion
* **Telegraphic speech**: early multi-word utterances (e.g., “want juice”)

> 🔍 **Research Spotlight**: By 6 months, infants can recognize their name and segment word boundaries using statistical cues.

> 🎧 **In class**: We’ll listen to babbling samples and discuss their diagnostic features.

---

### 3. Theoretical Approaches to Language Acquisition

#### Nativist Theories (Chomsky)

* **Universal Grammar (UG)**: humans are born with innate language principles
* Language input triggers parameter setting
* Poverty of the Stimulus argument: input is insufficient; knowledge must be innate

#### Empiricist Theories (Behaviorist & Connectionist)

* Learning occurs through **association, imitation, reinforcement**
* Connectionist models: neural networks learn through exposure

#### Interactionist Theories

* Emphasize social interaction and **input richness**
* **Child-Directed Speech (CDS)**: exaggerated intonation, slower tempo, simplified structure

> 👶 **Cross-linguistic Note**: CDS appears universally, but its features vary by culture and language.

> 🧪 **In class**: We’ll evaluate what each theory explains well and where it falls short.

---

### 4. The Role of Input and Environment

* Children need **exposure** to language in meaningful contexts
* Quality of input affects acquisition speed and vocabulary growth
* Deaf children not exposed to sign develop *home signs*, showing drive for communication

> 🧠 Language acquisition is resilient but shaped by input: children invent systems when needed, yet benefit from rich exposure.

---

## 🔁 Summary Table

| Concept              | Description                              | Example                                  |
| -------------------- | ---------------------------------------- | ---------------------------------------- |
| Babbling             | Early repetitive vocalizations           | "ba-ba", "da-da"                         |
| Universal Grammar    | Innate language structure                | Subject-verb-object ordering             |
| CDS                  | Simplified, expressive speech to infants | “Do you want your bottle?”               |
| Vocabulary Explosion | Rapid word learning                      | 18–24 months: \~10–20 new words/day      |
| Home Sign            | Invented sign system by deaf children    | Gestures to express requests or emotions |

---

## 📝 Self-Review Questions

1. What are the major milestones in early language development?
2. What is the difference between canonical and variegated babbling?
3. How do nativist and empiricist theories explain language learning?
4. What role does child-directed speech play in acquisition?
5. What do home sign systems reveal about the necessity of input?

---

## 📂 In-Class Resources and References

* 🎧 *Infant Speech Samples*: Babbling and early word recordings
* 📄 *Theory Comparison Chart*: UG vs. Behaviorism vs. Interactionism
* 🧬 *Poverty of the Stimulus*: Excerpts from Chomsky’s argument
* 📚 *Optional Reading*: Kuhl (2004), “Early language acquisition: Cracking the speech code” in *Nature Reviews Neuroscience*

---

> 📖 Reading: Chapter 3, pp. 42–63 from *Introduction to Psycholinguistics* by Traxler
-->

